# Введение в мониторинг приложений

Добро пожаловать в новый модуль!

К этому моменту вы уже знаете, как запускать приложения в Kubernetes, упаковывать их в Helm-чарты, масштабировать и создавать отказоустойчивую инфраструктуру. Однако, без мониторинга Kubernetes-кластер остаётся «чёрным ящиком» — мы не видим, что происходит внутри.

В этом модуле мы разберёмся с мониторингом: зачем он нужен, как его правильно использовать и какие инструменты могут помочь интегрировать мониторинг с Kubernetes.

## Зачем нужен мониторинг?

Мониторинг позволяет собирать и анализировать количественные данные о работе системы в реальном времени, прогнозировать проблемы, получать уведомления об ошибках и выявлять тенденции производительности.

Мониторинг решает три основные задачи:
- **Оповещение:** предупреждение об инцидентах.
- **Отладка:** сбор данных для анализа проблем.
- **Анализ тенденций:** планирование ресурсов и предотвращение сбоев.

## Основные понятия

- **Метрики** — численные показатели состояния и производительности приложения (например, количество свободного места на диске или время ответа сервиса).
- **SLA** (Service Level Agreement) — соглашение между поставщиком услуги и клиентом, описывающее целевые показатели качества.
- **SLI** (Service Level Indicator) — конкретные измеряемые показатели производительности (например, процент успешных запросов).
- **SLO** (Service Level Objective) — внутренние цели команды по достижению показателей, указанных в SLA.

## Типы мониторинга

Мониторинг делится на три уровня:
- **Бизнес-метрики:** количественные (например, число заказов) и качественные (например, удовлетворённость пользователей).
- **Прикладной мониторинг:** данные работы приложений (например, время ответа на запросы).
- **Мониторинг инфраструктуры:** состояние аппаратного и программного обеспечения (например, загрузка CPU и памяти).

## Подходы к мониторингу

- **Black-box и White-box:**
  - *Black-box* оценивает внешние симптомы и состояние системы (загрузка CPU, диска, памяти).
  - *White-box* собирает метрики изнутри приложения, позволяя выявлять проблемы до их появления.

- **Четыре золотых сигнала (LETS):**
  - Latency (задержка)
  - Errors (ошибки)
  - Traffic (трафик)
  - Saturation (насыщение)

- **Метод RED:**
  - Rate (частота запросов)
  - Errors (ошибки запросов)
  - Duration (длительность обработки запросов)

- **Метод USE:**
  - Utilization (утилизация ресурсов)
  - Saturation (насыщение, перегрузка)
  - Errors (ошибки использования ресурсов)

## Мониторинг в Kubernetes

Контейнеры в Kubernetes эфемерны и часто пересоздаются, что делает традиционные методы мониторинга неэффективными. Kubernetes требует специального подхода с централизованным сбором и хранением метрик, корреляцией метрик между сервисами и распределёнными трассировками запросов.

В Kubernetes необходимо отслеживать:
- Состояние подов (запущены ли контейнеры, ошибки запуска).
- Потребление ресурсов (CPU, память).
- Ошибки в приложении (например, HTTP 500).
- Производительность (нагрузка, задержки ответов).

Теперь вы знаете, зачем нужен мониторинг, какие существуют подходы и как интегрировать мониторинг в Kubernetes для эффективной работы приложений.

## Мониторинг приложений Kubernetes с помощью Prometheus

В этом модуле вы познакомитесь с инструментом мониторинга Prometheus и научитесь использовать его для сбора, анализа и визуализации метрик в Kubernetes.

### Что такое Prometheus?
Prometheus — популярный инструмент для мониторинга приложений и инфраструктуры. Его ключевые компоненты:
- **Prometheus Server** — собирает и хранит метрики в базе данных временных рядов (TSDB).
- **Exporter (экспортёр)** — источник метрик (например, NodeExporter, Kube State Metrics).
- **Alertmanager** — отправляет оповещения при достижении пороговых значений.
- **Grafana и Prometheus WEB-UI** — инструменты для визуализации метрик.
- **PromQL** — гибкий язык запросов для анализа данных.

### Особенности Prometheus
- Поддерживает модель сбора метрик Pull и Push (через Pushgateway).
- Динамическое определение целей мониторинга с помощью Service Discovery.
- Встроенная система оповещения через Alertmanager.
- Высокая производительность TSDB для работы с временными рядами.

### Типы метрик в Prometheus
- **Counter** — счётчик (например, количество запросов).
- **Gauge** — произвольные значения (например, текущее использование памяти).
- **Histogram** — гистограмма, измеряющая распределение значений (например, время обработки запросов).
- **Summary** — сводка для оценки квантилей измерений.

### Сбор метрик в Kubernetes
Prometheus в Kubernetes можно настроить с помощью:
- **ServiceMonitor** — собирает метрики с сервисов.
- **PodMonitor** — собирает метрики непосредственно с подов.
- **Prometheus Operator** — автоматизирует настройку и управление мониторингом.

### Язык запросов PromQL
Используется для анализа и визуализации метрик:
- Поддерживает арифметические операции и агрегацию данных.
- Примеры запросов:
  - `rate()` — вычисляет скорость изменения метрик.
  - `sum(rate(http_requests_total[5m])) by (pod)` — подсчёт количества запросов по подам.
  - `histogram_quantile()` — вычисляет перцентили значений из гистограмм.

### Практическое применение
Используя Prometheus в Kubernetes, вы сможете:
- Отслеживать производительность и ошибки приложений.
- Анализировать использование ресурсов.
- Настроить автоматическое масштабирование на основе собранных данных.

## Продвинутые стратегии масштабирования с использованием Prometheus

В этом разделе вы узнаете, как настраивать гибкое и точное масштабирование приложений в Kubernetes, используя пользовательские метрики, собираемые с помощью Prometheus.

### Зачем нужны пользовательские метрики?

Стандартные метрики (CPU, память) не всегда точно отражают реальную нагрузку приложения. Существуют сценарии, когда:
- Прокси-серверы обрабатывают множество соединений с низкой нагрузкой на CPU.
- Фоновые процессы (например, обработчики очередей) не загружают ресурсы, но должны масштабироваться при росте очередей.
- Пиковые нагрузки, которые не коррелируют с загрузкой CPU или памяти.

### Использование Prometheus Adapter

Prometheus Adapter позволяет использовать любые метрики из Prometheus для автоматического масштабирования:
- Adapter собирает и преобразует метрики Prometheus.
- Метрики становятся доступны через Custom Metrics API или External Metrics API Kubernetes.
- Контроллер HPA использует эти метрики для принятия решений о масштабировании.

### Настройка Prometheus Adapter

Правила сопоставления (mapping rules) задаются в конфигурации:

```yaml
rules:
  custom:
  - seriesQuery: 'promhttp_metric_handler_requests_total{code="200"}'
    resources:
      overrides:
        namespace:
          resource: namespace
        service:
          resource: service
    name:
      matches: "^promhttp_metric_handler_requests_total"
      as: "http_requests_per_minute"
    metricsQuery: 'sum(rate(promhttp_metric_handler_requests_total{code="200",service="podinfo"}[1m])) by (namespace, service) * 60'
```

### Применение пользовательских метрик в HPA

Пример конфигурации HPA с использованием пользовательских метрик:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: podinfo
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: podinfo
  minReplicas: 1
  maxReplicas: 3
  metrics:
    - type: Object
      object:
        describedObject:
          kind: Service
          name: podinfo
        metric:
          name: http_requests_per_minute
        target:
          type: Value
          value: "2000m"
```

### Оптимизация масштабирования

Параметры конфигурации HPA для предотвращения нестабильного масштабирования (flapping):

- **`stabilizationWindowSeconds`** — период стабилизации перед изменением количества подов.
- **`scaleUp` и `scaleDown`** — настройка скорости увеличения или уменьшения реплик.

Пример:

```yaml
behavior:
  scaleUp:
    policies:
      - type: Pods
        value: 2
        periodSeconds: 15
  scaleDown:
    policies:
      - type: Percent
        value: 25
        periodSeconds: 20
```

### Реальный кейс масштабирования

Новостной сайт масштабируется по пользовательской метрике (количество запросов):
- Минимум 2 реплики для стабильности.
- Максимум 20 реплик для пиковых нагрузок.
- Порог: 300 запросов в минуту на один под.
- Параметр стабилизации: 30 секунд для избежания избыточных скачков масштабирования.

### KEDA — альтернативный подход

KEDA позволяет масштабировать приложения на основе внешних событий (очереди сообщений, базы данных и другие источники метрик).

Теперь вы готовы применять продвинутые стратегии масштабирования на практике и создавать эффективную инфраструктуру с использованием Prometheus!